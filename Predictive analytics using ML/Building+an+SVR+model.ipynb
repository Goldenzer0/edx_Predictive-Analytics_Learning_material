{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a support vector regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now build a support vector regression for the medical data set on diabetes progression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a dataset included in scikit-learn. This returns a dataset as dictionary which contains the description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### added line to ensure plots are showing\n",
    "%matplotlib inline\n",
    "#####\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "dataset = load_diabetes()\n",
    "\n",
    "X = pd.DataFrame(data=dataset['data'],columns=dataset['feature_names'])\n",
    "\n",
    "# Again, best to scale the input variables\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "y = pd.DataFrame(data=dataset['target'],columns=['progression'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can almost use exactly the same code as for classification, except we use an instance of ```SVR```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 72.80139783435952\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "svr = SVR(gamma='auto')\n",
    "svr.fit(X_train,y_train.values.ravel())\n",
    "prediction = svr.predict(X_test)\n",
    "print('RMSE:', np.sqrt(mse(y_test,prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also change the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE (+/- standard deviation), for parameters\n",
      "59.161 (+/- 20.675) for {'C': 0.2, 'kernel': 'linear'}\n",
      "73.295 (+/- 31.148) for {'C': 0.2, 'kernel': 'poly'}\n",
      "76.273 (+/- 32.118) for {'C': 0.2, 'kernel': 'rbf'}\n",
      "57.085 (+/- 16.917) for {'C': 0.5, 'kernel': 'linear'}\n",
      "70.146 (+/- 29.609) for {'C': 0.5, 'kernel': 'poly'}\n",
      "74.700 (+/- 31.962) for {'C': 0.5, 'kernel': 'rbf'}\n",
      "56.098 (+/- 17.921) for {'C': 1.0, 'kernel': 'linear'}\n",
      "68.219 (+/- 29.209) for {'C': 1.0, 'kernel': 'poly'}\n",
      "72.501 (+/- 31.595) for {'C': 1.0, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# C is regularization parameter, default=1.0\n",
    "parameters = {'kernel':['linear','poly','rbf'],'C':[0.2,0.5,1.0]}\n",
    "\n",
    "grid_search = GridSearchCV(SVR(gamma='auto'), parameters, cv=5,scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "\n",
    "print('Mean RMSE (+/- standard deviation), for parameters')\n",
    "for mean, std, params in zip(means, stds, grid_search.cv_results_['params']):\n",
    "    print(\"%0.3f (+/- %0.03f) for %r\"\n",
    "          # The MSE is return as a negative, so we multiple it with -1 before squaring it\n",
    "          % (np.sqrt(-1*mean), np.sqrt(std), params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that, again, the linear kernel is working best with the cost parameter only influencing the result slightly. The confidence intervals are quite wide, however, so the results might not be very reliable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
